{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description about dataset::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
    "\n",
    "\n",
    "### Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Load Data\n",
    "\n",
    "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
    "\n",
    "3.Standardized the Input Variables. \n",
    "\n",
    "4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
    "\n",
    "5.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
    "\n",
    "6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
    "\n",
    "7.Train the Model with Epochs (100).\n",
    "\n",
    "8.If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "\n",
    "9.Prediction should be > 92%\n",
    "10.Evaluation Step\n",
    "11Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify fraudulent credit card transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/creditcardfraud/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:, :-1]\n",
    "targets = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 30)\n",
      "(284807,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, train_targets, validation_targets = train_test_split(train_data, train_targets, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_data)\n",
    "std = np.std(train_data)\n",
    "\n",
    "\n",
    "train_data -= mean\n",
    "train_data /= std\n",
    "\n",
    "validation_data -= mean\n",
    "validation_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(10, input_shape=(train_data.shape[1],), activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(6, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4985/4985 [==============================] - 25s 5ms/step - loss: 0.0430 - accuracy: 0.9986 - val_loss: 0.0066 - val_accuracy: 0.9994\n",
      "Epoch 2/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: 0.0073 - val_accuracy: 0.9994\n",
      "Epoch 3/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0061 - accuracy: 0.9996 - val_loss: 0.0070 - val_accuracy: 0.9994\n",
      "Epoch 4/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
      "Epoch 5/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 0.0053 - val_accuracy: 0.9994\n",
      "Epoch 6/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.0055 - val_accuracy: 0.9994\n",
      "Epoch 7/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0078 - accuracy: 0.9994 - val_loss: 0.0051 - val_accuracy: 0.9995\n",
      "Epoch 8/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
      "Epoch 9/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.0040 - val_accuracy: 0.9995\n",
      "Epoch 10/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 0.0053 - val_accuracy: 0.9994\n",
      "Epoch 11/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.0038 - val_accuracy: 0.9995\n",
      "Epoch 12/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.0040 - val_accuracy: 0.9995\n",
      "Epoch 13/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "Epoch 14/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
      "Epoch 15/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "Epoch 16/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "Epoch 17/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
      "Epoch 18/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.0059 - val_accuracy: 0.9995\n",
      "Epoch 19/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "Epoch 20/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "Epoch 21/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 22/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "Epoch 23/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9995\n",
      "Epoch 24/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "Epoch 25/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.0045 - val_accuracy: 0.9994\n",
      "Epoch 26/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.0060 - val_accuracy: 0.9994\n",
      "Epoch 27/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0073 - accuracy: 0.9994 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "Epoch 28/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.0043 - val_accuracy: 0.9995\n",
      "Epoch 29/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.0043 - val_accuracy: 0.9995\n",
      "Epoch 30/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.0043 - val_accuracy: 0.9995\n",
      "Epoch 31/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.0058 - val_accuracy: 0.9995\n",
      "Epoch 32/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.0047 - val_accuracy: 0.9995\n",
      "Epoch 33/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 34/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "Epoch 35/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.0052 - val_accuracy: 0.9995\n",
      "Epoch 36/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.0050 - val_accuracy: 0.9995\n",
      "Epoch 37/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0056 - accuracy: 0.9995 - val_loss: 0.0046 - val_accuracy: 0.9993\n",
      "Epoch 38/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0061 - val_accuracy: 0.9995\n",
      "Epoch 39/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9994\n",
      "Epoch 40/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9994\n",
      "Epoch 41/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0056 - accuracy: 0.9995 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "Epoch 42/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "Epoch 43/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "Epoch 44/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.0049 - val_accuracy: 0.9994\n",
      "Epoch 45/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.0049 - val_accuracy: 0.9995\n",
      "Epoch 46/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0059 - val_accuracy: 0.9994\n",
      "Epoch 47/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0074 - val_accuracy: 0.9994\n",
      "Epoch 48/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0089 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9995\n",
      "Epoch 49/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.0058 - val_accuracy: 0.9995\n",
      "Epoch 50/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.0052 - val_accuracy: 0.9995\n",
      "Epoch 51/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9995\n",
      "Epoch 52/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 53/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9995\n",
      "Epoch 54/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 55/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0054 - val_accuracy: 0.9995\n",
      "Epoch 56/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.0059 - val_accuracy: 0.9995\n",
      "Epoch 57/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 0.0074 - val_accuracy: 0.9994\n",
      "Epoch 58/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.0052 - val_accuracy: 0.9994\n",
      "Epoch 59/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9995\n",
      "Epoch 60/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.0069 - val_accuracy: 0.9994\n",
      "Epoch 61/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0078 - accuracy: 0.9993 - val_loss: 0.0063 - val_accuracy: 0.9995\n",
      "Epoch 62/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0067 - accuracy: 0.9993 - val_loss: 0.0092 - val_accuracy: 0.9994\n",
      "Epoch 63/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 0.0065 - val_accuracy: 0.9994\n",
      "Epoch 64/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.0057 - val_accuracy: 0.9994\n",
      "Epoch 65/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "Epoch 66/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.0057 - val_accuracy: 0.9995\n",
      "Epoch 67/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.0082 - val_accuracy: 0.9994\n",
      "Epoch 68/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.0062 - val_accuracy: 0.9995\n",
      "Epoch 69/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.0053 - val_accuracy: 0.9991\n",
      "Epoch 70/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9994\n",
      "Epoch 71/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.0049 - val_accuracy: 0.9994\n",
      "Epoch 72/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.0053 - val_accuracy: 0.9993\n",
      "Epoch 73/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.0066 - val_accuracy: 0.9994\n",
      "Epoch 74/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 0.0078 - val_accuracy: 0.9995\n",
      "Epoch 75/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 0.0056 - val_accuracy: 0.9994\n",
      "Epoch 76/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9994\n",
      "Epoch 77/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.0064 - val_accuracy: 0.9994\n",
      "Epoch 78/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.0057 - val_accuracy: 0.9994\n",
      "Epoch 79/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 80/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.0043 - val_accuracy: 0.9995\n",
      "Epoch 81/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.0048 - val_accuracy: 0.9994\n",
      "Epoch 82/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "Epoch 83/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 84/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0042 - val_accuracy: 0.9995\n",
      "Epoch 85/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.0055 - val_accuracy: 0.9994\n",
      "Epoch 86/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.0045 - val_accuracy: 0.9994\n",
      "Epoch 87/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.0047 - val_accuracy: 0.9995\n",
      "Epoch 88/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9995\n",
      "Epoch 89/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9995\n",
      "Epoch 90/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 0.0041 - val_accuracy: 0.9995\n",
      "Epoch 91/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 0.0097 - val_accuracy: 0.9995\n",
      "Epoch 92/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 0.0084 - val_accuracy: 0.9995\n",
      "Epoch 93/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0098 - val_accuracy: 0.9995\n",
      "Epoch 94/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.0069 - val_accuracy: 0.9994\n",
      "Epoch 95/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 0.0065 - val_accuracy: 0.9994\n",
      "Epoch 96/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 97/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.0085 - val_accuracy: 0.9995\n",
      "Epoch 98/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 99/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.0080 - val_accuracy: 0.9994\n",
      "Epoch 100/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.0077 - val_accuracy: 0.9994\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_targets, epochs=100, validation_data=(validation_data, validation_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['accuracy']\n",
    "val_loss = history.history['val_accuracy']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2671/2671 [==============================] - 3s 935us/step - loss: 0.0084 - accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.008442030288279057, 0.9992860555648804]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 99.9% accuracy without handling imbalanced data.... ðŸ¤”ðŸ¤¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.reshape(85443)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({'Actual': test_targets, 'Prediction': np.round(predictions)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233727</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264809</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243161</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47288</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180822</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Actual  Prediction\n",
       "233727       0         0.0\n",
       "264809       0         0.0\n",
       "243161       0         0.0\n",
       "47288        0         0.0\n",
       "180822       0         0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many correct predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85382, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = (output_df.loc[:, 'Actual'] == output_df.loc[:, 'Prediction'])\n",
    "\n",
    "output_df[filt].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 99.92860737567734%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy is {(output_df[filt].shape[0]/output_df.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Work - Imbalanced Data\n",
    "\n",
    "-> finding ROC AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.889948298351997"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(test_targets, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this is an excellent classifier according to this post [here](https://www.researchgate.net/post/What-is-the-value-of-the-area-under-the-roc-curve-AUC-to-conclude-that-a-classifier-is-excellent#:~:text=for%20Atomic%20Research-,What%20is%20the%20value%20of%20the%20area%20under%20the%20roc,1%20denotes%20an%20excellent%20classifier.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Weighted Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    159214\n",
       "1       277\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 277 1's (frauds) and 159215 0's (non-frauds)\n",
    "\n",
    "159215/277 = 574\n",
    "\n",
    "0's are 574 times more than 1's\n",
    "\n",
    "we can assign custom weights to NN accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    0:1,\n",
    "    1:570\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4985/4985 [==============================] - 25s 5ms/step - loss: 2.3137 - accuracy: 0.9806 - val_loss: 0.0094 - val_accuracy: 0.9993\n",
      "Epoch 2/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 3.1956 - accuracy: 0.9993 - val_loss: 0.0095 - val_accuracy: 0.9994\n",
      "Epoch 3/100\n",
      "4985/4985 [==============================] - 7s 2ms/step - loss: 1.7960 - accuracy: 0.9994 - val_loss: 0.0096 - val_accuracy: 0.9994\n",
      "Epoch 4/100\n",
      "4985/4985 [==============================] - 7s 2ms/step - loss: 1.8852 - accuracy: 0.9994 - val_loss: 0.0094 - val_accuracy: 0.9994\n",
      "Epoch 5/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 2.0950 - accuracy: 0.9994 - val_loss: 0.0142 - val_accuracy: 0.9994\n",
      "Epoch 6/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.5259 - accuracy: 0.9994 - val_loss: 0.0631 - val_accuracy: 0.9984\n",
      "Epoch 7/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.3273 - accuracy: 0.9990 - val_loss: 0.0094 - val_accuracy: 0.9994\n",
      "Epoch 8/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.2960 - accuracy: 0.9993 - val_loss: 0.0088 - val_accuracy: 0.9994\n",
      "Epoch 9/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.6479 - accuracy: 0.9992 - val_loss: 0.0356 - val_accuracy: 0.9994\n",
      "Epoch 10/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.4006 - accuracy: 0.9990 - val_loss: 0.0073 - val_accuracy: 0.9994\n",
      "Epoch 11/100\n",
      "4985/4985 [==============================] - 7s 2ms/step - loss: 1.3166 - accuracy: 0.9993 - val_loss: 0.0079 - val_accuracy: 0.9994\n",
      "Epoch 12/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.1966 - accuracy: 0.9955 - val_loss: 0.0092 - val_accuracy: 0.9994\n",
      "Epoch 13/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.1625 - accuracy: 0.9913 - val_loss: 0.2879 - val_accuracy: 0.9722\n",
      "Epoch 14/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.1472 - accuracy: 0.9867 - val_loss: 0.0073 - val_accuracy: 0.9994\n",
      "Epoch 15/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.7627 - accuracy: 0.9933 - val_loss: 0.0308 - val_accuracy: 0.9994\n",
      "Epoch 16/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.2970 - accuracy: 0.9891 - val_loss: 0.0558 - val_accuracy: 0.9993\n",
      "Epoch 17/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2702 - accuracy: 0.9817 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
      "Epoch 18/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.2874 - accuracy: 0.9923 - val_loss: 0.0081 - val_accuracy: 0.9994\n",
      "Epoch 19/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2980 - accuracy: 0.9916 - val_loss: 0.0119 - val_accuracy: 0.9994\n",
      "Epoch 20/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.0887 - accuracy: 0.9907 - val_loss: 0.0182 - val_accuracy: 0.9994\n",
      "Epoch 21/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2933 - accuracy: 0.9811 - val_loss: 0.0199 - val_accuracy: 0.9994\n",
      "Epoch 22/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2237 - accuracy: 0.9865 - val_loss: 0.0101 - val_accuracy: 0.9994\n",
      "Epoch 23/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.3716 - accuracy: 0.9843 - val_loss: 0.0081 - val_accuracy: 0.9994\n",
      "Epoch 24/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.6834 - accuracy: 0.9646 - val_loss: 0.0082 - val_accuracy: 0.9994\n",
      "Epoch 25/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2438 - accuracy: 0.9782 - val_loss: 0.0107 - val_accuracy: 0.9994\n",
      "Epoch 26/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.2611 - accuracy: 0.9838 - val_loss: 0.0158 - val_accuracy: 0.9993\n",
      "Epoch 27/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.4229 - accuracy: 0.9714 - val_loss: 0.0094 - val_accuracy: 0.9994\n",
      "Epoch 28/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4477 - accuracy: 0.9652 - val_loss: 0.1459 - val_accuracy: 0.9927\n",
      "Epoch 29/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.1370 - accuracy: 0.9690 - val_loss: 0.0173 - val_accuracy: 0.9993\n",
      "Epoch 30/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 0.9129 - accuracy: 0.9756 - val_loss: 0.0274 - val_accuracy: 0.9989\n",
      "Epoch 31/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.2150 - accuracy: 0.9732 - val_loss: 0.1601 - val_accuracy: 0.9944\n",
      "Epoch 32/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2189 - accuracy: 0.9495 - val_loss: 0.0106 - val_accuracy: 0.9994\n",
      "Epoch 33/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.2310 - accuracy: 0.9793 - val_loss: 0.0287 - val_accuracy: 0.9989\n",
      "Epoch 34/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.1462 - accuracy: 0.9507 - val_loss: 0.2312 - val_accuracy: 0.9801\n",
      "Epoch 35/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.3485 - accuracy: 0.9568 - val_loss: 0.0167 - val_accuracy: 0.9992\n",
      "Epoch 36/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.1531 - accuracy: 0.9578 - val_loss: 0.0099 - val_accuracy: 0.9994\n",
      "Epoch 37/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4512 - accuracy: 0.9681 - val_loss: 0.0098 - val_accuracy: 0.9994\n",
      "Epoch 38/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.6136 - accuracy: 0.9472 - val_loss: 0.0106 - val_accuracy: 0.9993\n",
      "Epoch 39/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2826 - accuracy: 0.9583 - val_loss: 0.0098 - val_accuracy: 0.9994\n",
      "Epoch 40/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.1967 - accuracy: 0.9488 - val_loss: 0.0108 - val_accuracy: 0.9994\n",
      "Epoch 41/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.3965 - accuracy: 0.9586 - val_loss: 0.0087 - val_accuracy: 0.9994\n",
      "Epoch 42/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2851 - accuracy: 0.9526 - val_loss: 0.0256 - val_accuracy: 0.9992\n",
      "Epoch 43/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.0474 - accuracy: 0.9615 - val_loss: 0.0093 - val_accuracy: 0.9994\n",
      "Epoch 44/100\n",
      "4985/4985 [==============================] - 7s 2ms/step - loss: 1.3905 - accuracy: 0.9454 - val_loss: 0.0088 - val_accuracy: 0.9994\n",
      "Epoch 45/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.5392 - accuracy: 0.9590 - val_loss: 0.0081 - val_accuracy: 0.9994\n",
      "Epoch 46/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.1702 - accuracy: 0.9576 - val_loss: 0.0079 - val_accuracy: 0.9994\n",
      "Epoch 47/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.3855 - accuracy: 0.9458 - val_loss: 0.6976 - val_accuracy: 0.5203\n",
      "Epoch 48/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.6263 - accuracy: 0.9460 - val_loss: 0.0940 - val_accuracy: 0.9990\n",
      "Epoch 49/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.3630 - accuracy: 0.9529 - val_loss: 0.1257 - val_accuracy: 0.9966\n",
      "Epoch 50/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.1950 - accuracy: 0.9419 - val_loss: 0.0079 - val_accuracy: 0.9994\n",
      "Epoch 51/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2580 - accuracy: 0.9640 - val_loss: 0.0088 - val_accuracy: 0.9994\n",
      "Epoch 52/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2267 - accuracy: 0.9398 - val_loss: 0.0347 - val_accuracy: 0.9991\n",
      "Epoch 53/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.0160 - accuracy: 0.9567 - val_loss: 0.0073 - val_accuracy: 0.9994\n",
      "Epoch 54/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.3651 - accuracy: 0.9436 - val_loss: 0.0093 - val_accuracy: 0.9994\n",
      "Epoch 55/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4593 - accuracy: 0.9601 - val_loss: 0.0083 - val_accuracy: 0.9994\n",
      "Epoch 56/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4730 - accuracy: 0.9365 - val_loss: 0.0178 - val_accuracy: 0.9993\n",
      "Epoch 57/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.2957 - accuracy: 0.9380 - val_loss: 0.0087 - val_accuracy: 0.9994\n",
      "Epoch 58/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4379 - accuracy: 0.9455 - val_loss: 0.0381 - val_accuracy: 0.9987\n",
      "Epoch 59/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2785 - accuracy: 0.9401 - val_loss: 0.1628 - val_accuracy: 0.9770\n",
      "Epoch 60/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2889 - accuracy: 0.9412 - val_loss: 0.0071 - val_accuracy: 0.9994\n",
      "Epoch 61/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.4355 - accuracy: 0.9418 - val_loss: 0.0072 - val_accuracy: 0.9994\n",
      "Epoch 62/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.5327 - accuracy: 0.9546 - val_loss: 0.0233 - val_accuracy: 0.9984\n",
      "Epoch 63/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.1814 - accuracy: 0.9519 - val_loss: 0.0067 - val_accuracy: 0.9994\n",
      "Epoch 64/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.1299 - accuracy: 0.9540 - val_loss: 1.5907 - val_accuracy: 0.1982\n",
      "Epoch 65/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.3772 - accuracy: 0.9335 - val_loss: 0.0127 - val_accuracy: 0.9990\n",
      "Epoch 66/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4980 - accuracy: 0.9496 - val_loss: 2.5607 - val_accuracy: 0.0732\n",
      "Epoch 67/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2183 - accuracy: 0.9377 - val_loss: 0.0150 - val_accuracy: 0.9990\n",
      "Epoch 68/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.3036 - accuracy: 0.9285 - val_loss: 0.0154 - val_accuracy: 0.9989\n",
      "Epoch 69/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4651 - accuracy: 0.9357 - val_loss: 0.0202 - val_accuracy: 0.9989\n",
      "Epoch 70/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.9032 - accuracy: 0.9232 - val_loss: 0.1134 - val_accuracy: 0.9983\n",
      "Epoch 71/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2093 - accuracy: 0.9420 - val_loss: 0.0375 - val_accuracy: 0.9993\n",
      "Epoch 72/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.6045 - accuracy: 0.9335 - val_loss: 2.7558 - val_accuracy: 0.0073\n",
      "Epoch 73/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4180 - accuracy: 0.9446 - val_loss: 0.0077 - val_accuracy: 0.9994\n",
      "Epoch 74/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.6003 - accuracy: 0.9609 - val_loss: 0.0113 - val_accuracy: 0.9990\n",
      "Epoch 75/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2712 - accuracy: 0.9483 - val_loss: 0.0071 - val_accuracy: 0.9993\n",
      "Epoch 76/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.5369 - accuracy: 0.9406 - val_loss: 0.1377 - val_accuracy: 0.9894\n",
      "Epoch 77/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4182 - accuracy: 0.9289 - val_loss: 0.0066 - val_accuracy: 0.9994\n",
      "Epoch 78/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.6075 - accuracy: 0.9400 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
      "Epoch 79/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.2962 - accuracy: 0.9539 - val_loss: 0.0090 - val_accuracy: 0.9994\n",
      "Epoch 80/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.5664 - accuracy: 0.9332 - val_loss: 0.0064 - val_accuracy: 0.9994\n",
      "Epoch 81/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4238 - accuracy: 0.9552 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
      "Epoch 82/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.6437 - accuracy: 0.9426 - val_loss: 0.0061 - val_accuracy: 0.9994\n",
      "Epoch 83/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.2920 - accuracy: 0.9383 - val_loss: 0.0211 - val_accuracy: 0.9992\n",
      "Epoch 84/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.3609 - accuracy: 0.9293 - val_loss: 0.0087 - val_accuracy: 0.9994\n",
      "Epoch 85/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.9015 - accuracy: 0.9319 - val_loss: 0.0070 - val_accuracy: 0.9994\n",
      "Epoch 86/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.5336 - accuracy: 0.9264 - val_loss: 2.7779 - val_accuracy: 0.0126\n",
      "Epoch 87/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.3081 - accuracy: 0.9416 - val_loss: 0.0092 - val_accuracy: 0.9994\n",
      "Epoch 88/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4807 - accuracy: 0.9411 - val_loss: 2.0994 - val_accuracy: 0.0435\n",
      "Epoch 89/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.3520 - accuracy: 0.9257 - val_loss: 0.5901 - val_accuracy: 0.6732\n",
      "Epoch 90/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4807 - accuracy: 0.9501 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
      "Epoch 91/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.3790 - accuracy: 0.9362 - val_loss: 0.0504 - val_accuracy: 0.9992\n",
      "Epoch 92/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.6031 - accuracy: 0.9389 - val_loss: 0.0080 - val_accuracy: 0.9994\n",
      "Epoch 93/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.7628 - accuracy: 0.9479 - val_loss: 0.1069 - val_accuracy: 0.9934\n",
      "Epoch 94/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.5607 - accuracy: 0.9274 - val_loss: 0.0101 - val_accuracy: 0.9991\n",
      "Epoch 95/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.9630 - accuracy: 0.9317 - val_loss: 0.0080 - val_accuracy: 0.9994\n",
      "Epoch 96/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.6710 - accuracy: 0.9148 - val_loss: 0.0080 - val_accuracy: 0.9994\n",
      "Epoch 97/100\n",
      "4985/4985 [==============================] - 7s 1ms/step - loss: 1.4931 - accuracy: 0.9470 - val_loss: 0.0381 - val_accuracy: 0.9986\n",
      "Epoch 98/100\n",
      "4985/4985 [==============================] - 7s 2ms/step - loss: 1.3149 - accuracy: 0.9452 - val_loss: 0.0302 - val_accuracy: 0.9986\n",
      "Epoch 99/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.2778 - accuracy: 0.9382 - val_loss: 0.0093 - val_accuracy: 0.9993\n",
      "Epoch 100/100\n",
      "4985/4985 [==============================] - 8s 2ms/step - loss: 1.2776 - accuracy: 0.9412 - val_loss: 0.0146 - val_accuracy: 0.9991\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(10, input_shape=(train_data.shape[1],), activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(6, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# CHANGE\n",
    "history = model.fit(train_data, train_targets, epochs=100, validation_data=(validation_data, validation_targets), class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9582468564743789"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(test_targets, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By using Cost Sensitive/ Weighted Neural Network, the ROC AUC Score is improved from 0.88 to 0.95 (outstanding classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2671/2671 [==============================] - 2s 914us/step - loss: 0.0133 - accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.013341130688786507, 0.9990988373756409]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
